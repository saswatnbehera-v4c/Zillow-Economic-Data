{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1132e37a-4132-42d7-8c9b-fb52df9c12c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../config/project_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba70766-3e3d-4407-96c1-5de73f2e7bee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Passed: Table has 4 historical versions.\n"
     ]
    }
   ],
   "source": [
    "history = spark.sql(f\"DESCRIBE HISTORY {CATALOG_NAME}.{SCHEMA_SILVER}.county_crosswalk_metrics\")\n",
    "# We expect at least version 0 (initial) and version 1 (standardized)\n",
    "version_count = history.count()\n",
    "assert version_count >= 2, f\"❌ Failed: Expected at least 2 versions, found{version_count}\"\n",
    "print(f\"✅ Passed: Table has {version_count} historical versions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aa4257c-f70f-4974-8ae1-72911ce8ee23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Passed: Time travel confirms migration from string to double.\n"
     ]
    }
   ],
   "source": [
    "df_old = spark.read.option(\"versionAsOf\", 0).table(f\"{CATALOG_NAME}.{SCHEMA_SILVER}.county_crosswalk_metrics\")\n",
    "\n",
    "df_new = spark.table(f\"{CATALOG_NAME}.{SCHEMA_SILVER}.county_crosswalk_metrics\")\n",
    "\n",
    "old_type = dict(df_old.dtypes)[\"zhvi_all_homes\"]\n",
    "new_type = dict(df_new.dtypes)[\"zhvi_all_homes\"]\n",
    "\n",
    "assert old_type == \"string\" and new_type == \"double\", f\"❌ Failed: Type changenot detected!\"\n",
    "print(f\"✅ Passed: Time travel confirms migration from {old_type} to {new_type}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2be8bfb9-9f6f-4b2a-af82-d0fa1f9a2d79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Passed: Time travel confirms migration from string to date.\n"
     ]
    }
   ],
   "source": [
    "df_old = spark.read.option(\"versionAsOf\", 0).table(f\"{CATALOG_NAME}.{SCHEMA_SILVER}.county_crosswalk_metrics\")\n",
    "\n",
    "df_new = spark.table(f\"{CATALOG_NAME}.{SCHEMA_SILVER}.county_crosswalk_metrics\")\n",
    "\n",
    "old_type = dict(df_old.dtypes)[\"date\"]\n",
    "new_type = dict(df_new.dtypes)[\"date\"]\n",
    "\n",
    "assert old_type == \"string\" and new_type == \"date\", f\"❌ Failed: Type changenot detected!\"\n",
    "print(f\"✅ Passed: Time travel confirms migration from {old_type} to {new_type}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c78fae6-8bb9-4cf9-a246-f4263d91e5ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_delta_features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}